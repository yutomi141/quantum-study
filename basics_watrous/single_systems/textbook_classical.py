#!/usr/bin/env python
# coding: utf-8

# {/* cspell:ignore Biggr, operatorname */}
# 
# 

# <span id="classical-information" />
# 
# # クラシック情報
# 
# 量子情報とその仕組みについて説明するために、まず <DefinitionTooltip definition="古典的という用語は、量子論が発見される以前の物理理論（ニュートン物理学など）に基づく概念、考え方、記述を指す。 情報の文脈では、量子情報とは特に関係のない意味として解釈される">クラシック</DefinitionTooltip>。
# 量子情報の講座で、なぜ古典的な情報にこれほど注目が集まるのか不思議に思うのは当然だが、それには理由がある。
# 
# ひとつには、量子情報と古典情報には壮大な違いがあるが、その数学的記述は実はよく似ている。
# 古典的な情報は、量子情報を研究する際の身近な参照点として、また驚くほど長い道のりをたどる類推の源としても役立つ。
# 量子情報に関して、人々が古典的な類似点を持つような質問をするのはよくあることで、そのような質問には単純な答えが返ってくることが多い。
# 実際、古典的な情報を理解することなしに、量子情報を真に理解することはできないと主張することは、まったく不合理なことではない。
# 
# 読者の中には、このセクションで取り上げる内容をすでに知っている人もいれば、そうでない人もいるだろう。
# このセクションでは、量子情報入門に最も関連する古典情報の側面に焦点を当てることに加えて、量子情報と計算でベクトルと行列を記述するためによく使われる*ディラック記法を*紹介する。
# 結局のところ、ディラック記法は量子情報に特化したものではなく、古典的な情報の文脈でも、またベクトルや行列が生じる他の多くの場面でも同じように使うことができる。
# 
# <span id="classical-states-and-probability-vectors" />
# 
# ## 古典的状態と確率ベクトル
# 
# 情報を保存する <DefinitionTooltip definition="このコースでは、システムとは情報を格納する物理的な装置や媒体を抽象化したものである。">システム</DefinitionTooltip>。
# より具体的には、この系は各瞬間に有限個の*古典的状態の*いずれかになりうると仮定する。
# ここで、 *古典的状態という*用語は、直感的な用語として理解されるべきで、一義的に認識され記述できる構成として理解されるべきである。
# 
# その典型的な例は*ビット*であり、その古典的状態は $0$ と である。 $1.$ 他の例としては、標準的な6面ダイスがあり、その古典的状態は $1,$ $2,$ $3,$ $4,$ $5,$ と $6$ （どの面が上であっても、対応する数の点で表される）、DNA鎖の核酸塩基があり、その古典的状態は *A*、 *C*、 *G*、 *T、* 扇風機のスイッチがあり、その古典的状態は（一般的に） *ハイ*、 *ミディアム*、 *ロー*、 *オフ*である。
# 数学的に言えば、システムの古典的状態の仕様は、実際には出発点です。ビットを古典的状態 $0$ と $1,$ を持つシステムとして*定義し*、異なる古典的状態セットを持つシステムについても同様です。
# 
# この議論のために、考えている系に $\mathsf{X}$ という名前をつけ、 $\Sigma$ という記号を使って、 の古典的状態の集合を指すことにする。 $\mathsf{X}.$ すでに述べた $\Sigma$ が有限であるという仮定に加え、 $\Sigma$ が*空でない*ことも当然仮定する。なぜなら、物理系がまったく状態を持たないのは非科学的だからである。
# また、物理系が*無限に*多くの古典的状態を持つことを考えるのは理にかなっているが、この可能性は確かに興味深いが、このコースには関係ないので無視することにする。
# このような理由から、また便宜上簡潔にするために、以下では、有限で空でない集合を意味する*古典的状態集合という*用語を使うことにする。
# 
# 例をいくつか示します。
# 
# 1.  $\mathsf{X}$ をビットとすると、 $\Sigma = \{0,1\}.$ この集合を*バイナリ・アルファベットと*呼ぶ。
# 2.  $\mathsf{X}$ を6面ダイスとする。 $\Sigma = \{1,2,3,4,5,6\}.$
# 3.  $\mathsf{X}$ が電動ファンスイッチの場合 $\Sigma = \{\mathrm{high}, \mathrm{medium}, \mathrm{low}, \mathrm{off}\}.$
# 
# $\mathsf{X}$、情報のキャリアとして考えるとき、 $\mathsf{X}$ の異なる古典的な状態は、異なる結果や結末をもたらす、ある意味を持つ。
# そのような場合は、 $\mathsf{X}$、単にその可能な古典的状態のひとつにあると表現すれば十分かもしれない。
# たとえば、 $\mathsf{X}$ がファンのスイッチだとすると、それが*高に*設定されていることを偶然にも確実に知っていた場合、それを*中くらいに*切り替えることになるかもしれない
# 
# しかし、情報処理において、我々の知識が不確かであることはよくある。
# システムの古典的状態に関する知識を表現する一つの方法として、 $\mathsf{X}$、さまざまな可能性のある古典的*状態に* *確率を*関連付けることができる。
# 
# 例えば、 $\mathsf{X}$ がビットだとする。
# 過去に $\mathsf{X}$ に起こったことについて私たちが知っていること、あるいは期待することに基づけば、私たちはおそらく、 $\mathsf{X}$ が古典的な状態 $0$ にある確率は $3/4$ であり、 $1$ の状態にある確率は であると信じるかもしれない。 $1/4.$ このような信念をこう書くことで表すことができる：
# 
# $$
# \operatorname{Pr}(\mathsf{X}=0) = \frac{3}{4}
# \quad\text{and}\quad
# \operatorname{Pr}(\mathsf{X}=1) = \frac{1}{4}.
# $$
# 
# この確率的状態をより簡潔に表現する方法は、列ベクトルである。
# 
# $$
# \begin{pmatrix}
#   \frac{3}{4}\\[2mm]
#   \frac{1}{4}
# \end{pmatrix}
# $$
# 
# ビットが $0$ である確率はベクトルの一番上に置かれ、ビットが $1$ である確率は一番下に置かれる。 $\{0,1\}.$
# 
# 一般に、任意の古典的状態集合を持つシステムの確率的状態は、同じように確率のベクトルとして表現できる。
# 確率はどのようにでも並べることができるが、自然な、あるいはデフォルトの方法があるのが一般的だ。 正確には、2つの性質を満たす列ベクトルによって、あらゆる確率的状態を表すことができる：
# 
# 1.  ベクトルのすべてのエントリは*非負の実数*である。
# 2.  エントリーの合計は次のようになる。 $1.$
# 
# 逆に言えば、この2つの性質を満たす列ベクトルは、確率的な状態を表すものとみなすことができる。
# 以下、この形式のベクトルを*確率ベクトルと*呼ぶ。
# 
# この表記法の簡潔さと同時に、確率的状態を列ベクトルとして識別することで、確率的状態に対する演算が行列とベクトルの掛け算で表現できるという利点がある。
# 
# <span id="measuring-probabilistic-states" />
# 
# ## 確率的状態の測定
# 
# 次に、システムが確率的な状態にあるときに、それを*測定*するとどうなるかを考えてみよう。 この文脈では、システムを測定するということは、単にシステムを見て、それがどんな古典的な状態であれ、曖昧さなく認識することを意味する。 直感的に言えば、私たちはシステムの確率的状態を「見る」ことはできない。
# 
# システムを測定することで、そのシステムに関する知識も変化する可能性があり、その結果、システムに関連付ける確率的状態も変化する可能性がある。
# つまり、 $\mathsf{X}$ が古典的な状態 $a\in\Sigma,$ にあることを認識した場合、 $\mathsf{X}$ の状態に関する我々の知識を表す新しい確率ベクトルは、 $a$ に対応するエントリに $1$ を持ち、他のすべてのエントリに $0$ を持つベクトルとなる。
# $\vert a\rangle,$ $a$ このベクトルは、 $\mathsf{X}$ が古典的な状態 $a$ にあることを確実に示している。
# この種のベクトルは*標準基底*ベクトルとも呼ばれる。
# 
# 例えば、我々が考えているシステムがビットであると仮定すると、標準基底ベクトルは次式で与えられる
# 
# $$
#   \vert 0\rangle = \begin{pmatrix}1\\[1mm] 0\end{pmatrix}
#   \quad\text{and}\quad
#   \vert 1\rangle = \begin{pmatrix}0\\[1mm] 1\end{pmatrix}.
# $$
# 
# 任意の2次元列ベクトルは、これら2つのベクトルの線形結合として表現できることに注意。
# 例:
# 
# $$
# \begin{pmatrix}
#   \frac{3}{4}\\[2mm]
#   \frac{1}{4}
# \end{pmatrix}
# = \frac{3}{4}\,\vert 0\rangle + \frac{1}{4}\,\vert 1\rangle.
# $$
# 
# どの列ベクトルも標準基底状態の線形結合として書くことができる。
# ベクトルをこのように表現することはよくある。
# 
# 測定されることによって確率的な状態が変化することに話を戻すと、私たちの日常的な経験と次のようなつながりがあることに気づくだろう。
# 公平なコインを裏返したが、見る前にコインを覆ったとする。
# そして、その確率的状態は次のようになる
# 
# $$
# \begin{pmatrix}
#   \frac{1}{2}\\[2mm]
#   \frac{1}{2}
# \end{pmatrix}
# = \frac{1}{2}\,\vert\text{heads}\rangle + \frac{1}{2}\,\vert\text{tails}\rangle.
# $$
# 
# ここで、コインの古典的な状態集合は $\{\text{heads},\text{tails}\}.$、これらの状態を最初に表、次に裏として並べることにする。
# 
# $$
# \vert\text{heads}\rangle = \begin{pmatrix}1\\[1mm] 0\end{pmatrix}
# \quad\text{and}\quad
# \vert\text{tails}\rangle = \begin{pmatrix}0\\[1mm] 1\end{pmatrix}
# $$
# 
# もしコインを取り出して見れば、古典的な2つの状態、つまり表か裏のどちらかが見えるだろう。
# 仮にその結果が「表」であったとすると、コインの確率的状態の記述は当然更新され、次のようになる。 $|\text{tails}\rangle.$ もちろん、その後コインを覆い隠し、その後コインを取り出してもう一度見たとしても、古典的な状態は依然として表であり、これは確率的状態がベクトル $|\text{tails}\rangle.$
# 
# これは些細なことに思えるかもしれないし、ある意味ではそうだ。
# しかし、量子系は完全に類似した振る舞いをする一方で、その測定特性はしばしば奇妙または異常とみなされる。
# 古典的なシステムに類似した性質を確立することで、量子情報の働きはそれほど珍しいものではないと思われるかもしれない。
# 
# 確率的状態の測定に関して最後にひとつだけ言っておきたいことがある： 確率的状態は知識や信念を記述するものであり、必ずしも実際のものを記述するものではない。
# 例えば、コインをひっくり返した後、見る前のコインの状態は、表か裏のどちらかである。
# 例えば、古典的な状態が表であることを見たとき、私たちは当然、私たちの知識を表すベクトルを $|\text{tails}\rangle,$。しかし、コインが発見されたとき、それを見なかった他の誰かにとっては、確率的状態は変化しない。
# 個人によって、あるシステムについての知識や信念が異なることがあり、したがって、そのシステムを異なる確率ベクトルで記述することがある。
# 
# <span id="classical-operations" />
# 
# ## クラシカル・オペレーション
# 
# 古典的な情報についてのこの簡単なまとめの最後の部分では、古典的なシステムで実行できる操作の種類を考えてみよう。
# 
# <span id="deterministic-operations" />
# 
# ### 決定論的操作
# 
# まず、 <DefinitionTooltip definition="操作の結果が入力によって完全に決定され、偶然や不確実性の要素がない場合、その操作は決定論的である。">決定論</DefinitionTooltip> 操作がある。ここで、各古典的状態 $a\in\Sigma$ は、ある形式の関数 $f$ に対して、 $f(a)$ に変換される。 $f:\Sigma\rightarrow\Sigma.$
# 
# 例えば、 $\Sigma = \{0,1\},$ の場合、 $f_1,$、 $f_2,$、 $f_3,$、 $f_4,$ の4つの関数があり、これらは次のような値の表で表すことができる：
# 
# $$
# \begin{array}{c|c}
#   a & f_1(a)\\
#   \hline
#   0 & 0\\
#   1 & 0
# \end{array}
# \qquad
# \begin{array}{c|c}
#   a & f_2(a)\\
#   \hline
#   0 & 0\\
#   1 & 1
# \end{array}
# \qquad
# \begin{array}{c|c}
#   a & f_3(a)\\
#   \hline
#   0 & 1\\
#   1 & 0
# \end{array}
# \qquad
# \begin{array}{c|c}
#   a & f_4(a)\\
#   \hline
#   0 & 1\\
#   1 & 1
# \end{array}
# $$
# 
# これらの関数の最初と最後は*一定である：* $f_1(a) = 0$、 $f_4(a) = 1$。 $a\in\Sigma.$ 真ん中の2つは一定ではなく、 *釣り合いがとれて*いる。 (この場合は1回)である。
# 関数 $f_2$ は、 <DefinitionTooltip definition="identity関数は入力を変更せずに返す。">同一関数</DefinitionTooltip> : $f_2(a) = a$ の各関数である。 $a\in\Sigma.$ そして $f_3$ は関数 $f_3(0) = 1$ と $f_3(1) = 0,$ で、NOT 関数としてよく知られている。
# 
# 確率的状態に対する決定論的操作の作用は、行列とベクトルの乗算で表すことができる。
# 具体的には、与えられた関数 $f:\Sigma\rightarrow\Sigma$ を表す行列 $M$ は、以下を満たすものである
# 
# $$
# M \vert a \rangle = \vert f(a)\rangle
# $$
# 
# すべての $a\in\Sigma.$ このような行列は常に存在し、この要件によって一意に決定される。
# 決定論的操作を表す行列は、常に各列に $1$、それ以外の項目には $0$。
# 
# 例えば、上記の関数 $f_1,\ldots,f_4$ に対応する行列 $M_1,\ldots,M_4$ は以下の通りである：
# 
# $$
#   M_1 =
#   \begin{pmatrix}
#     1 & 1\\
#     0 & 0
#   \end{pmatrix},
#   \hspace{4mm}
#   M_2 =
#   \begin{pmatrix}
#     1 & 0\\
#     0 & 1
#   \end{pmatrix},
#   \hspace{4mm}
#   M_3 =
#   \begin{pmatrix}
#     0 & 1\\
#     1 & 0
#   \end{pmatrix},
#   \hspace{4mm}
#   M_4 =
#   \begin{pmatrix}
#     0 & 0\\
#     1 & 1
#   \end{pmatrix}.
# $$
# 
# 最初の行列が正しいことを示す簡単な検証である。
# 他の3つも同様にチェックできる。
# 
# $$
# \begin{aligned}
# M_1 \vert 0\rangle
# & =
# \begin{pmatrix}
#   1 & 1\\
#   0 & 0
# \end{pmatrix}
# \begin{pmatrix}
#   1\\
#   0
# \end{pmatrix}
# = \begin{pmatrix}
#   1\\
#   0
# \end{pmatrix}
# = \vert 0\rangle = \vert f_1(0)\rangle \\[4mm]
# M_1 \vert 1\rangle
# & =
# \begin{pmatrix}
#   1 & 1\\
#   0 & 0
# \end{pmatrix}
# \begin{pmatrix}
#   0\\
#   1
# \end{pmatrix}
# = \begin{pmatrix}
#   1\\
#   0
# \end{pmatrix}
# = \vert 0\rangle = \vert f_1(1)\rangle
# \end{aligned}
# $$
# 
# これらの形式や他の形式の行列を表現する便利な方法は、先に述べた列ベクトル用の表記法に類似した行ベクトル用の表記法を用いることである。 $a$ に対応するエントリーに $1$ を持ち、他のすべてのエントリーにゼロを持つ*行*ベクトルを、 $\langle a \vert$ で表す。 $a\in\Sigma.$ このベクトルは "bra $a.$ " と読む。
# 
# 例えば、 $\Sigma = \{0,1\},$
# 
# $$
#   \langle 0 \vert = \begin{pmatrix}
#     1 & 0
#   \end{pmatrix}
#   \quad\text{and}\quad
#   \langle 1 \vert = \begin{pmatrix}
#     0 & 1
#   \end{pmatrix}.
# $$
# 
# 任意の古典状態集合 $\Sigma,$ に対して、行ベクトルと列ベクトルを行列と見なし、行列の乗算を実行することができる。 $\vert b\rangle \langle a\vert.$ $(b,a),$ の組に対応するエントリーに $1$ を持つ正方行列が得られる。これは、そのエントリーの行が古典的状態 $b$ に対応し、列が古典的状態 $a,$ に対応することを意味し、他のすべてのエントリーは $0$ である。 例:
# 
# $$
#   \vert 0 \rangle \langle 1 \vert =
#   \begin{pmatrix}
#   1\\
#   0
#   \end{pmatrix}
#   \begin{pmatrix}
#   0 & 1
#   \end{pmatrix} =
#   \begin{pmatrix}
#     0 & 1 \\
#     0 & 0
#   \end{pmatrix}.
# $$
# 
# この表記法を用いると、任意の関数 $f:\Sigma\rightarrow\Sigma$ に対応する行列 $M$ を次のように表すことができる
# 
# $$
#   M = \sum_{a\in\Sigma} \vert f(a) \rangle \langle a \vert.
# $$
# 
# 例えば、上記の関数 $f_4$ を考えてみよう。 $\Sigma = \{0,1\}.$ 以下のような行列が得られる
# 
# $$
# M_4 = \vert f_4(0) \rangle \langle 0 \vert + \vert f_4(1) \rangle \langle 1 \vert
# = \vert 1\rangle \langle 0\vert + \vert 1\rangle \langle 1\vert
# = \begin{pmatrix}
# 0 & 0\\
# 1 & 0
# \end{pmatrix} +
# \begin{pmatrix}
# 0 & 0\\
# 0 & 1
# \end{pmatrix}
# = \begin{pmatrix}
# 0 & 0\\
# 1 & 1
# \end{pmatrix}.
# $$
# 
# その理由は以下の通りである。
# 再びベクトルを行列として考え、今度は乗算を考える $\langle a \vert \vert b \rangle,$、スカラー（つまり数）として考えることができる $1\times 1$ 行列が得られる。
# 整頓のため、この積を $\langle a \vert b\rangle$ と書く。 $\langle a \vert \vert b \rangle.$ この積は次の簡単な式を満たす：
# 
# $$
#   \langle a \vert b \rangle
#   = \begin{cases}
#     1 & a = b\\[1mm]
#     0 & a \neq b.
#   \end{cases}
# $$
# 
# この観察と、行列の掛け算が連想的かつ線形であるという事実を利用すると、次のようになる
# 
# $$
#   M \vert b \rangle =
#   \Biggl(
#   \sum_{a\in\Sigma} \vert f(a) \rangle \langle a \vert
#   \Biggr)
#   \vert b\rangle
#   = \sum_{a\in\Sigma} \vert f(a) \rangle \langle a \vert b \rangle
#   = \vert f(b)\rangle,
# $$
# 
# それぞれの $b\in\Sigma,$、これはまさに我々が行列に要求していることである。 $M.$
# 
# 後のレッスンで詳しく説明しますが、 $\langle a \vert b \rangle$ は、 $\vert a\rangle$ と の間の*内積と*見なすこともできます。 $\vert b\rangle.$ 内積は量子情報において決定的に重要であるが、その議論は必要になってからにしよう。
# 
# この時点で、"bra "と "ket "という名称は明らかだろう。"bra" $\langle a\vert$ と "ket" $\vert b\rangle$ を一緒にすると、"bracket "ができる。 $\langle a \vert b\rangle.$ この表記法と用語は <DefinitionTooltip definition="ポール・ディラックは量子物理学の発展に大きく貢献した物理学者である。">ポール・ディラック</DefinitionTooltip> によるもので、そのため*ディラック表記法として*知られている。
# 
# <span id="probabilistic-operations-and-stochastic-matrices" />
# 
# ### 確率演算と確率行列
# 
# 決定論的操作に加えて、 *確率論的操作が*ある。
# 
# 例えば、ビットに対する次のような操作を考えてみよう。
# ビットの古典的状態が $0,$ の場合はそのままである。ビットの古典的状態が $1,$ の場合は反転され、確率 $0$ で $1/2$、確率 $1$ で となる。 $1/2.$ この操作は行列
# 
# $$
#   \begin{pmatrix}
#     1 & \frac{1}{2}\\[1mm]
#     0 & \frac{1}{2}
#   \end{pmatrix}.
# $$
# 
# この行列に2つの標準基底ベクトルを掛け合わせることで、この行列が正しい働きをすることを確認できる。
# 
# 古典的な状態集合を任意に選択した場合、すべての確率的操作の集合を数学的な言葉で表現すると、これらの2つの性質を満たす行列である <DefinitionTooltip definition="ストキャスティック（stochastic）とは、おおよそランダムという意味だ。 確率行列はランダムな過程を表す。">確率的</DefinitionTooltip> ：
# 
# 1.  すべての項目は非負の実数である。
# 2.  各列のエントリーの合計は $1.$
# 
# 同様に、確率行列は列がすべて確率ベクトルを形成する行列である。
# 
# 直感的なレベルでは、確率的な操作とは、上の例のように、操作中に何らかの形でランダム性が使われたり、導入されたりするようなものだと考えることができる。
# 確率的操作の確率行列記述に関しては、各列は、その列に対応する古典的状態入力が与えられたときに生成される確率的状態のベクトル表現と見なすことができる。
# 
# 確率行列とは、確率ベクトルを常に確率ベクトルに写像する行列のことだと考えることもできる。
# つまり、確率行列は常に確率ベクトルを確率ベクトルに写像し、常に確率ベクトルを確率ベクトルに写像する行列は確率行列でなければならない。
# 
# 最後に、確率的操作について別の見方をすれば、決定論的*操作の*ランダムな選択ということになる。
# 例えば、上の例の操作は、同一関数か定数0の関数を、それぞれ確率で適用していると考えることができる。 $1/2.$ これは
# 
# $$
#   \begin{pmatrix}
#     1 & \frac{1}{2}\\[1mm]
#     0 & \frac{1}{2}
#   \end{pmatrix}
#   = \frac{1}{2}
#   \begin{pmatrix}
#     1 & 0\\[1mm]
#     0 & 1
#   \end{pmatrix}
#   + \frac{1}{2}
#   \begin{pmatrix}
#     1 & 1\\[1mm]
#     0 & 0
#   \end{pmatrix}.
# $$
# 
# このような式は、古典的状態集合と、その古典的状態集合と同定された行と列を持つ確率行列の任意の選択に対して、常に可能である。
# 
# <span id="compositions-of-probabilistic-operations" />
# 
# ### 確率的操作の構成
# 
# $\mathsf{X}$ が古典的な状態集合を持つシステムであるとする。 $\Sigma,$ と $M_1,\ldots,M_n$ は、システムに対する確率的操作を表す確率行列である。 $\mathsf{X}.$
# 
# 確率ベクトル $u,$ で表される確率的状態に最初の操作 $M_1$ を適用すると、結果として確率的状態はベクトルで表される。 $M_1 u.$ この新しい確率ベクトルに第二の確率演算 $M_2$ を適用すると、確率ベクトルは次のようになる。
# 
# $$
#   M_2 (M_1 u) = (M_2 M_1) u.
# $$
# 
# この等式は、行列の乗算（特別な場合として行列とベクトルの乗算を含む）が <DefinitionTooltip definition="括弧の位置を動かしても同じ結果が得られるなら、演算は連想的である。">連想</DefinitionTooltip> 操作であるという事実から導かれる。
# したがって、 <DefinitionTooltip definition="コンポジションとは、ある機能や操作を別の機能の後に適用することを指す。">合成</DefinitionTooltip>、まず $M_1$、次に $M_2,$、第1と第2の確率的演算を適用して得られる確率的演算は、必然的に確率的である行列 $M_2 M_1,$。
# 
# より一般的には、行列 $M_1,\ldots,M_n$ で表される確率的操作をこの順序で合成する、つまり、 $M_1$ が最初に適用され、 $M_2$ が二番目に適用され、 $M_n$ が最後に適用される、ということは、次のように表される。 行列積
# 
# $$
#   M_n \,\cdots\, M_1.
# $$
# 
# 行列の乗算は連想演算ではあるが、 <DefinitionTooltip definition="入力の順番を入れ替えても結果が変わらない場合、演算は可換である。">可換の</DefinitionTooltip>。
# 例えば、
# 
# $$
#   M_1 =
#   \begin{pmatrix}
#     1 & 1\\[1mm]
#     0 & 0
#   \end{pmatrix}
#   \quad\text{and}\quad
#   M_2 =
#   \begin{pmatrix}
#     0 & 1\\[1mm]
#     1 & 0
#   \end{pmatrix},
# $$
# 
# その場合
# 
# $$
#   M_2 M_1 =
#   \begin{pmatrix}
#     0 & 0 \\[1mm]
#     1 & 1
#   \end{pmatrix}
#   \quad\text{and}\quad
#   M_1 M_2 =
#   \begin{pmatrix}
#     1 & 1\\[1mm]
#     0 & 0
#   \end{pmatrix}.
# $$
# 
# つまり、確率的操作を構成する順番が重要なのである。構成の中で操作を適用する順番を変えると、結果として得られる操作が変わる可能性がある。
# 
# 

# © IBM Corp., 2017-2025
